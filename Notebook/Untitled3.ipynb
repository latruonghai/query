{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from truyvan.truyVan import TruyVan\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDF(TruyVan):\n",
    "    def __init__(self, tv, data):\n",
    "        super().__init__(tv, data)\n",
    "        \n",
    "    def parseWord(self, file_paths):\n",
    "        lst_contents = []\n",
    "        dictionary = set()\n",
    "        for path in file_paths:\n",
    "            with open(path,'r') as file:\n",
    "                string = file.read()\n",
    "                # Loai bo ki tu dac biet\n",
    "                content = re.sub('[^\\w\\s\\=/%-]','',string).split()\n",
    "                lst_contents.append(content)\n",
    "                dictionary.update(content)\n",
    "        dictionary = list(dictionary)\n",
    "        return (dictionary, lst_contents)\n",
    "    \n",
    "    def tf(self, terms, contents):\n",
    "        dic = {}\n",
    "        l = len(contents)\n",
    "        for index1, word in enumerate(terms):\n",
    "            #print(word)\n",
    "            n = 0\n",
    "            TF = []\n",
    "            for index2, content in enumerate(contents):\n",
    "                #print(content)\n",
    "                if word in content:\n",
    "                    TF.append([index2, content.count(word)/len(content)])\n",
    "                    n +=1\n",
    "            try:\n",
    "                idf = math.log(l/n)\n",
    "            except ZeroDivisionError:\n",
    "                idf = math.log(l)\n",
    "            if len(TF) > 0:\n",
    "                TF.append(idf)\n",
    "                dic[word] = TF\n",
    "            else:\n",
    "                dic[word] = [[0]]\n",
    "        return dic\n",
    "    def tf_idf_calc(self, dic):\n",
    "        for key in dic.keys():\n",
    "            term = dic[key]\n",
    "            id = term[0][0]\n",
    "            #print(term[-1])\n",
    "            tf_IDF = term[0][1]*term[-1]\n",
    "            dic[key] = [id, tf_IDF]\n",
    "        return dic\n",
    "    def tf_idf_calc1(self, dic, idf):\n",
    "        for index, key in enumerate(dic.keys()):\n",
    "            term1 = dic[key]\n",
    "            tem1 = []\n",
    "            for i in range(len(term1)-1) :\n",
    "                txt = term1[i]\n",
    "                id = txt[0]\n",
    "                tf_IDF = txt[-1]*idf[index]\n",
    "                tem1.append([id, tf_IDF])\n",
    "            dic[key] = tem1\n",
    "        return dic\n",
    "    def Logic(self,clauses, logic):\n",
    "        pass\n",
    "            \n",
    "        return words\n",
    "def tfidf(arr, idf):\n",
    "    for tf in arr:\n",
    "        tf[1] *= idf\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/lahai/DATA/Study/DAI HOC/NamBa/TruyVan/Tuan4/src/wikipedia/Tào_Tháo/cNXu-9.txt\n"
     ]
    }
   ],
   "source": [
    "tv = \"'Lưu' and 'Tháo' and 'đi' and 'ngủ'\"\n",
    "data = '/media/lahai/DATA/Study/DAI HOC/NamBa/TruyVan/Tuan4/src/wikipedia/Tào_Tháo/*.txt'\n",
    "tf_idf = TFIDF(tv, data)\n",
    "files_path = tf_idf.filePaths(tf_idf.data)\n",
    "dictionary, lst_contents = tf_idf.parseWord(files_path)\n",
    "#print(term)\n",
    "term, logic = tf_idf.defTerm()\n",
    "print(files_path[15])\n",
    "text = tf_idf.tf(dictionary, lst_contents)\n",
    "idf = [i[-1] for i in a.values()]\n",
    "query  = tf_idf.tf(dictionary, [term])\n",
    "# Tinh TF, IDF cua text\n",
    "text = tf_idf.tf_idf_calc1(text,idf)\n",
    "# Tinh TF, IDF cua query\n",
    "query = tf_idf.tf_idf_calc1(query,idf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loai bo trong so == 0\n",
    "def RutGon(dic):\n",
    "    dics = {}\n",
    "    for key, value in dic.items():\n",
    "        if len(value) >0:\n",
    "            dics[key] = value[0][-1]\n",
    "    return dics\n",
    "q = RutGon(be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tinh space vector\n",
    "Dic = {}\n",
    "for key, values in q.items():\n",
    "\n",
    "    new_list = he[key]\n",
    "    for i in he[key]:\n",
    "        id = i[0]\n",
    "        value1 = i[-1]\n",
    "    try:\n",
    "        Dic[id] += values*value1\n",
    "    except KeyError:\n",
    "        Dic[id] = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('foo': conda)",
   "language": "python",
   "name": "python38364bitfoocondaa93fb2234420416a9eaa26ad5f935624"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
