Lý do phi công Mỹ thua trắng trước trí tuệ nhân tạo
Cơ quan Nghiên cứu Các dự án Quốc phòng Tiên tiến (DARPA) thuộc Lầu Năm Góc hồi tháng 8 tiến hành đợt thử nghiệm mô phỏng không chiến tầm gần trên máy tính mang tên Alpha Dogfight. Trong cuộc đấu này, một phi công hàng đầu của Mỹ có mật danh "Banger" đeo kính thực tế ảo, sử dụng buồng lái mô phỏng để điều khiển tiêm kích F-16 không chiến tầm gần với chiến đấu cơ do trí tuệ nhân tạo (AI) của công ty Heron Systems điều khiển. Tiêm kích do AI điều khiển nhanh chóng hạ chiếc F-16 do Banger cầm lái trong 4 trận đánh đầu tiên. Phi công Mỹ cố thay đổi chiến thuật trong lượt đấu cuối cùng, nhưng vẫn không bắn trúng được phát nào và bị AI hạ gục ngay sau đó. Giới chuyên gia nhận định có nhiều nguyên nhân khiến phi công Mỹ thua trắng trước trí tuệ nhân tạo, đồng thời cảnh báo những rủi ro tiềm tàng trong sử dụng AI vào mục đích quân sự. Theo chuyên gia quân sự Sebastien Roblin, phi công AI đã vượt giới hạn của con người trong thử nghiệm khi liên tục tung đòn tấn công chính xác trong thời gian rất ngắn. Nó cũng tận dụng tối đa giới hạn chịu đựng của khung thân máy bay, trong khi trí tuệ nhân tạo không chịu tác động của tình trạng quá tải gia tốc trong các động tác cơ động phức tạp như con người. AI của Heron Systems sử dụng hình thức học tăng cường sâu (DRL), trong đó máy tính mô phỏng chiến đấu liên tục không nghỉ. Ban đầu, phi công AI chỉ học cách tránh để tiêm kích lao xuống đất. Tuy nhiên, sau khoảng 4 tỷ lần mô phỏng chiến đấu, AI của Heron Systems đã làm chủ được các kỹ năng cơ động trong không chiến tầm gần. Con người có thể khai thác hạn chế của AI như cách Banger đối phó máy tính trong trận đấu cuối. Tuy nhiên, phi công AI có thể nhanh chóng rút ra bài học từ những thất bại và tự cải thiện năng lực tác chiến. Trọng tâm thử nghiệm là không chiến bằng pháo ở tầm gần, khiến các nhà tổ chức không thử thách được AI trong các nhiệm vụ phức tạp như sử dụng cảm biến tầm xa và tên lửa. Đây là những yếu tố có thể quyết định kết quả trận không chiến từ trước khi hai bên tiến vào tầm nhìn thị giác của nhau. Ngoài ra, hình thức tác chiến một đấu một trong mô phỏng cũng khác xa thực tế, khi mỗi bên có thể được hàng chục tàu mặt nước và đơn vị phòng không yểm trợ. Phương thức học máy của AI cũng có những hạn chế lớn. Phi công AI có thể gặp khó trong làm việc theo nhóm. Dữ liệu đầu vào hạn chế cũng khiến mô hình học thông qua thử nghiệm tạo ra những kết quả không tối ưu khi đối mặt với tình huống mới. Theo Roblin, phụ thuộc vào AI cũng tiềm ẩn những rủi ro. Hầu hết máy bay không người lái (UAV) ngày nay do con người điều khiển từ xa, kết hợp với thuật toán tự động để tránh va chạm và tự trở về căn cứ khi mất kết nối với hệ thống kiểm soát mặt đất. Việc điều khiển từ xa sẽ khiến UAV không thể di chuyển với tốc độ cao và tấn công chính xác. Xu hướng chủ đạo trong quân sự hiện nay là sử dụng tiêm kích có người lái để điều phối UAV trang bị AI trong các nhiệm vụ cụ thể, nhiều rủi ro như tấn công theo bầy đàn và chế áp hệ thống phòng không đối phương. Những hệ thống này luôn đối mặt nguy cơ bị can thiệp, khiến chúng mất khả năng tác chiến hoặc thậm chí rơi vào tay đối phương. Những cỗ máy chiến tranh tự động trong tương lai cũng làm dấy lên lo ngại về mặt đạo đức khi chúng không có cảm xúc như con người. UAV trang bị AI nhận diện khuôn mặt có thể gặp lỗi nghiêm trọng và tung đòn tấn công bừa bãi. "Đợt thử nghiệm Alpha Dogfight cho thấy AI vượt trội con người khi cần tính toán nhanh và chính xác trong cuộc tranh tài với quy định rõ ràng. Tuy nhiên, khả năng ra quyết định linh hoạt và hợp tác trong môi trường bất ổn của chiến tranh công nghệ cao vẫn là dấu hỏi lớn", Roblin nói. Duy Sơn (Theo CNBC)